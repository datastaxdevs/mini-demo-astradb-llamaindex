{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d60a143-5cc8-43b9-8f2b-d5353aaa7f3c",
   "metadata": {},
   "source": [
    "# Integrate LlamaIndex with Astra DB Serverless\n",
    "\n",
    "For more information, visit the DataStax [Astra DB docs page](https://docs.datastax.com/en/astra/astra-db-vector/integrations/llamaindex.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943defcb-ace5-4d78-82e3-37b0a24dbc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install --quiet \"llama-index==0.10.15\" \\\n",
    "  \"llama-index-vector-stores-astra-db>=0.1.3\" \\\n",
    "  \"python-dotenv==1.0.1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d863d3c-8778-4109-a1ae-f6b81fee6fc9",
   "metadata": {},
   "source": [
    "## Secrets\n",
    "\n",
    "Example values:\n",
    "- API Endpoint: `\"https://01234567-89ab-cdef-0123-456789abcdef-us-east1.apps.astra.datastax.com\"`\n",
    "- Token: `\"AstraCS:6gBhNmsk135...\"` (it must have a role of at least \"Database Administrator\")\n",
    "- OpenAI API key: `sk-4fQ3F...`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47802c94-ec4a-460b-ba01-cbeff5c9c060",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "os.environ[\"ASTRA_DB_APPLICATION_TOKEN\"] = getpass(\"ASTRA_DB_APPLICATION_TOKEN = \")\n",
    "os.environ[\"ASTRA_DB_API_ENDPOINT\"] = input(\"ASTRA_DB_API_ENDPOINT = \")\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass(\"OPENAI_API_KEY = \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb0accf-a225-4333-9164-746f3a8df124",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98830bd7-0daf-4e46-a2d6-98642cbcd54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from llama_index.vector_stores.astra_db import AstraDBVectorStore\n",
    "from llama_index.core import VectorStoreIndex, StorageContext\n",
    "from llama_index.core.llama_dataset import download_llama_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfaaff0-f2f1-4245-82fb-92f3a4b44b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "ASTRA_DB_APPLICATION_TOKEN = os.environ.get(\"ASTRA_DB_APPLICATION_TOKEN\")\n",
    "ASTRA_DB_API_ENDPOINT = os.environ.get(\"ASTRA_DB_API_ENDPOINT\")\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78db8321-0ba0-4620-b552-e7e924804405",
   "metadata": {},
   "source": [
    "## Download and inspect LlamaHub dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f327321-bf8b-4db4-ab2b-71f63ab72829",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_dataset, documents = download_llama_dataset(\n",
    "  \"PaulGrahamEssayDataset\", \"./data\"\n",
    ")\n",
    "\n",
    "print(f\"Number of loaded documents: {len(documents)}\")\n",
    "print(f\"First document, id: {documents[0].doc_id}\")\n",
    "print(f\"First document, hash: {documents[0].hash}\")\n",
    "print(\n",
    "    \"First document, text\"\n",
    "    f\" ({len(documents[0].text)} characters):\\n\"\n",
    "    f\"{'=' * 20}\\n\"\n",
    "    f\"{documents[0].text[:360]} ...\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d001b63a-7ff2-49e7-865a-a955504912de",
   "metadata": {},
   "source": [
    "## (Optional) See chunking in action\n",
    "\n",
    "_This can be skipped, it's here just for a quick peek at what LlamaIndex does internally upon document ingestion._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9859326a-92b5-4a31-87d8-4f32f9cd4c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This step is optional because splitting happens automatically during ingestion\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "default_splitter = SentenceSplitter()\n",
    "split_nodes = default_splitter(documents)\n",
    "print(f\"Number of split nodes: {len(split_nodes)}\")\n",
    "print(f\"Third split node, document reference ID: {split_nodes[2].ref_doc_id}\")\n",
    "print(f\"Third split node, node ID: {split_nodes[2].node_id}\")\n",
    "print(f\"Third split node, hash: {split_nodes[2].hash}\")\n",
    "print(\n",
    "    \"Third split node, text\"\n",
    "    f\" ({len(split_nodes[2].text)} characters):\\n\"\n",
    "    f\"{'=' * 20}\\n\"\n",
    "    f\"{split_nodes[2].text[:360]} ...\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d116494e-e3e0-4345-a3cc-268da354fe2e",
   "metadata": {},
   "source": [
    "## Create an Astra DB vector store (with its collection on DB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43669a4-0f13-4abc-8197-3b4336f7586c",
   "metadata": {},
   "outputs": [],
   "source": [
    "astra_db_store = AstraDBVectorStore(\n",
    "    token=ASTRA_DB_APPLICATION_TOKEN,\n",
    "    api_endpoint=ASTRA_DB_API_ENDPOINT,\n",
    "    collection_name=\"llama_index_rag_test\",\n",
    "    embedding_dimension=1536,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438a4548-988c-4c32-83c7-0502f3b1624a",
   "metadata": {},
   "source": [
    "## Load the documents in the vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80126487-5cfc-42d5-9643-0706f4f1662b",
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_context = StorageContext.from_defaults(vector_store=astra_db_store)\n",
    "\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents=documents, storage_context=storage_context\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded8ac62-73dd-4258-8cdd-bb4d754cc851",
   "metadata": {},
   "source": [
    "## Run a similarity search (to verify the integration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22c8276-8d87-4b15-a6d1-5aadf649bf87",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine()\n",
    "query_string_1 = \"Why did the author choose to work on AI?\"\n",
    "response = query_engine.query(query_string_1)\n",
    "\n",
    "print(\"\\n\\n\" + query_string_1)\n",
    "print(response.response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd961154-e33d-4eda-96ce-c7dd887354b0",
   "metadata": {},
   "source": [
    "## Further usage patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d22175b-4a7f-4ebb-936a-72db24551f56",
   "metadata": {},
   "source": [
    "### MMR (maximal marginal relevance) similarity search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523a1b18-8b81-484a-b79e-c8fa74ac5d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = index.as_retriever(\n",
    "    vector_store_query_mode=\"mmr\",\n",
    "    similarity_top_k=3,\n",
    "    vector_store_kwargs={\"mmr_prefetch_factor\": 4},\n",
    ")\n",
    "\n",
    "query_string_2 = \"Why did the author choose to work on AI?\"\n",
    "nodes_with_scores = retriever.retrieve(query_string_2)\n",
    "\n",
    "print(\"\\n\\n\" + query_string_2 + \" (question asked with MMR)\")\n",
    "print(f\"Found {len(nodes_with_scores)} nodes.\")\n",
    "for idx, node_with_score in enumerate(nodes_with_scores):\n",
    "    print(f\"    [{idx}] score = {node_with_score.score}\")\n",
    "    print(f\"        id    = {node_with_score.node.node_id}\")\n",
    "    print(f\"        text  = {node_with_score.node.text[:90]} ...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
